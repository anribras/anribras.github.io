---
layout: post
title:
modified:
categories: Tech
 
tags: [web,zeromq]

  
comments: true
---
<!-- TOC -->

- [中间件](#中间件)
- [m-n Pub-sub(The Dynamic Discovery Problem)](#m-n-pub-subthe-dynamic-discovery-problem)
    - [第1条pub message丢失?](#第1条pub-message丢失)
- [Transport Bridging(Forwarder)](#transport-bridgingforwarder)
- [Req-rep Shared Queue (DEALER and ROUTER sockets)](#req-rep-shared-queue-dealer-and-router-sockets)
- [Asynchronous client/server](#asynchronous-clientserver)
- [zmq_proxy](#zmq_proxy)

<!-- /TOC -->

## 中间件

就像生意里的批发商，渠道商,从上游进货，发售给下游，其存在是为了让复杂的网络变简单，更高效.

在ZeroMQ里，根据使用的背景不同，名称可多了:proxies, queues, forwarders, device, or brokers...

下面是列举了一些实际场景，看Zeromq怎么解决:


## m-n Pub-sub(The Dynamic Discovery Problem)

最简单的情况1 pub <-> n subs，但是m to n 呢?

![2018-09-12-09-24-27](https://images-1257933000.cos.ap-chengdu.myqcloud.com/2018-09-12-09-24-27.png)

直接上原文好了,和push-pull有区别吗？mute的策略不同.

We need XPUB and XSUB sockets because ZeroMQ does subscription forwarding from subscribers to publishers. XSUB and XPUB are exactly like SUB and PUB except they expose subscriptions as special messages. The proxy has to forward these subscription messages from subscriber side to publisher side, by reading them from the XSUB socket and writing them to the XPUB socket. This is the main use case for XSUB and XPUB.

publisher:
```py
import zmq
import time

context = zmq.Context()
sender = context.socket(zmq.PUB)
sender.connect("tcp://127.0.0.1:5559")

# send 3 but only 2 received by peer.
for i in range(3):
    sender.send(b'Hello there')
    time.sleep(1)
```
subscriber:
```py
import zmq

context = zmq.Context()
receiver = context.socket(zmq.SUB)
# Subscribe any topic
receiver.setsockopt(zmq.SUBSCRIBE, b'')

receiver.connect("tcp://127.0.0.1:5560")
while True:
    msg = receiver.recv_multipart()
    print('Subscriber got ', msg)

```
proxy:
```py
import zmq

context = zmq.Context()

frontend = context.socket(zmq.XSUB)
backend = context.socket(zmq.XPUB)

# Frontend as client , means forwarding one net to another.
# Frontend work as server, means a simple queue or broker
# fontend.connect("tcp://127.0.0.1:5559")
frontend.bind("tcp://127.0.0.1:5559")
backend.bind("tcp://127.0.0.1:5560")

zmq.proxy(frontend, backend)

# We never get here…
frontend.close()
backend.close()
context.term()
```

### 第1条pub message丢失?
上面的例子是subscriber先运行，再proxy,最后publisher.subscriber先运行时，publisher的第1条消息并没有收到, 更稳健的做法，增加一个req-rep的通知渠道，进行1次握手.

![2018-09-12-17-26-54](https://images-1257933000.cos.ap-chengdu.myqcloud.com/2018-09-12-17-26-54.png)

这个`REQ-REP`也可以直接用proxy的方式.subscriber收到publisher的hello后，给个yes，然后publisher才发送真正的消息.

stable-subscriber:
```py
import zmq

context = zmq.Context()

receiver = context.socket(zmq.SUB)

# Subscribe any topic
receiver.setsockopt(zmq.SUBSCRIBE, b'')
receiver.connect("tcp://127.0.0.1:5560")

controller = context.socket(zmq.REP)
controller.connect("tcp://127.0.0.1:5562")

req = controller.recv()
print('req = ', req)
if req == b'Hello':
    controller.send(b'yes')
    while True:
        msg = receiver.recv_multipart()
        print('Subscriber got ', msg)
else:
    print('Some error')
```
stable-publisher:
```py
import zmq
import time

context = zmq.Context()

sender = context.socket(zmq.PUB)
sender.connect("tcp://127.0.0.1:5559")

controller = context.socket(zmq.REQ)
controller.connect("tcp://127.0.0.1:5561")

controller.send(b'Hello')
rep = controller.recv()
print('rep = ', rep)
if rep == b'yes':
    for i in range(3):
        sender.send(b'Blablabla')
else:
    print("Some error")
```
rep-req proxy:
```py
import zmq

context = zmq.Context()

frontend = context.socket(zmq.ROUTER)
backend = context.socket(zmq.DEALER)

# Frontend as client , means forwarding one net to another.
# Frontend work as server, means a simple queue or broker
# fontend.connect("tcp://127.0.0.1:5559")
frontend.bind("tcp://127.0.0.1:5561")
backend.bind("tcp://127.0.0.1:5562")

zmq.proxy(frontend, backend)

# We never get here…
frontend.close()
backend.close()
context.term()
```
pub-sub proxy和上面一致.


 还可以进一步扩展下，publisher可根据收到的回应。控制subsriber的数量等.就是前面讲过的`Node Cordinnation`

## Transport Bridging(Forwarder)

和上面唯一不同，就是proxy里的XSUB变成了client,即XSUB connect 到 PUB(server)上，然后forward到external network. 也可以叫`bridge`,作用就是从1个网络到另1个网络的中间件.

也可以叫network的forward,即connect `10.1.1.0:8100`的subscirber也能和内部`192.168.55.210:5556`网一样subscribe相同的topic.

![2018-09-12-11-15-28](https://images-1257933000.cos.ap-chengdu.myqcloud.com/2018-09-12-11-15-28.png)

## Req-rep Shared Queue (DEALER and ROUTER sockets)

`REQ-REP`模型仅适用的简单的场景，而DEALER和ROUTER其实是扩展`REQ-REP`的功能，比如模拟一个类似AMQP里的borker，具有routing等功能, 实现了many-to-many的`REQ-REP`通信模型，需要增加服务能力的时候，只需要增加`borker`就可以扩展系统性能.

REQ(client)只需要和ROUTER对话

REP(server)只需要和DEALER对话;

中间的broker来做负载均衡，消息路由等.逻辑业务并没有改变，但server的能力大大增强，反向代理就这么个玩法? 

各种client的请求是怎么分发到不同的server backend?这个就是策略问题了.

在云框架下，可不只是web反向代理这么简单，应该是非常常见的:

![2018-09-11-10-09-47](https://images-1257933000.cos.ap-chengdu.myqcloud.com/2018-09-11-10-09-47.png)

来个直接实现的borker:

```python
import zmq

# context = zmq.Context)
context = zmq.Context.instance()

frontend = context.socket(zmq.ROUTER)
frontend.bind("tcp://127.0.0.1:5559")

backend = context.socket(zmq.DEALER)
backend.bind("tcp://127.0.0.1:5560")

# Initialize poll set
poller = zmq.Poller()
poller.register(frontend, zmq.POLLIN)
poller.register(backend, zmq.POLLIN)

# router got req, forward to dealer
# dealer got rep , forward to router
# multiply req and rep and can be welly handled .
while True:
    socks = dict(poller.poll())

    if socks.get(frontend) == zmq.POLLIN:
        message = frontend.recv_multipart()
        backend.send_multipart(message)

    if socks.get(backend) == zmq.POLLIN:
        message = backend.recv_multipart()
        frontend.send_multipart(message)
```

## Asynchronous client/server

这个和上面的区别在于用DEALER代替client的REQ 和server的REP,实现全部消息来回的异步client-server，更灵活,不再局限于REQ-REP的send.recv的模式.

`asyncsrv`实现:

```py
import zmq
import sys
import threading
import time
from random import randint, random

__author__ = "Felipe Cruz <felipecruz@loogica.net>"
__license__ = "MIT/X11"

def tprint(msg):
    """like print, but won't get newlines confused with multiple threads"""
    sys.stdout.write(msg + '\n')
    sys.stdout.flush()

class ClientTask(threading.Thread):
    """ClientTask"""
    def __init__(self, id):
        self.id = id
        threading.Thread.__init__ (self)

    def run(self):
        context = zmq.Context()
        socket = context.socket(zmq.DEALER)
        identity = u'----%d' % self.id
        socket.identity = identity.encode('ascii')
        socket.connect('tcp://localhost:5570')
        print('Client %s started' % (identity))
        poll = zmq.Poller()
        poll.register(socket, zmq.POLLIN)
        reqs = 0
        while True:
            reqs = reqs + 1
            print('Req #%d sent..' % (reqs))
            socket.send_string(u'request #%d' % (reqs))
            for i in range(5):
                sockets = dict(poll.poll(1000))
                if socket in sockets:
                    msg = socket.recv()
                    tprint('Client %s received: %s' % (identity, msg))

        socket.close()
        context.term()

class ServerTask(threading.Thread):
    """ServerTask"""
    def __init__(self):
        threading.Thread.__init__ (self)

    def run(self):
        context = zmq.Context()
        frontend = context.socket(zmq.ROUTER)
        frontend.bind('tcp://*:5570')

        backend = context.socket(zmq.DEALER)
        backend.bind('inproc://backend')

        workers = []
        for i in range(5):
            worker = ServerWorker(context)
            worker.start()
            workers.append(worker)

        zmq.proxy(frontend, backend)

        frontend.close()
        backend.close()
        context.term()

class ServerWorker(threading.Thread):
    """ServerWorker"""
    def __init__(self, context,id):
        threading.Thread.__init__ (self)
        self.context = context
        self.id = id

    def run(self):
        worker = self.context.socket(zmq.DEALER)
        worker.connect('inproc://backend')
        tprint('Worker-%d started'%self.id)
        while True:
            ident, msg = worker.recv_multipart()
            tprint('Worker-%d received %s from %s' % (self.id,msg, ident))
            replies = randint(0,4)
            for i in range(replies):
                time.sleep(1. / (randint(1,10)))
                worker.send_multipart([ident, msg])

        worker.close()

def main():
    """main function"""
    server = ServerTask()
    server.start()
    for i in range(3):
        client = ClientTask(i)
        client.start()

    server.join()

if __name__ == "__main__":
    main()
```

上面代码的架构是DEALER<->(DEALER<->ROUTER)<->DEALER

输出

```
Worker-0 started
Client ---0 started
Req #1 sent..
Client ---1 started
Req #1 sent..
Worker-1 started
Worker-2 started
Worker-3 started
Worker-4 started
Worker-server-0 received b'request #1' from b'---0'
Worker send 3 replys
Worker-server-1 received b'request #1' from b'---1'
Worker send 4 replys
Client ---2 started
Req #1 sent..
Worker-server-2 received b'request #1' from b'---2'
Worker send 0 replys
Client ---0 received: b'request #1'
Client ---1 received: b'request #1'
Client ---1 received: b'request #1'
Client ---0 received: b'request #1'
Client ---1 received: b'request #1'
Client ---1 received: b'request #1'
Client ---0 received: b'request #1'
Req #2 sent..
Worker-server-3 received b'request #2' from b'---1'
Worker send 4 replys
Client ---1 received: b'request #2'
Client ---1 received: b'request #2'
Client ---1 received: b'request #2'
Client ---1 received: b'request #2'
Req #2 sent..
Worker-server-4 received b'request #2' from b'---0'
Worker send 1 replys
Client ---0 received: b'request #2'
Req #3 sent..
Worker-server-0 received b'request #3' from b'---1'
Worker send 3 replys
Client ---1 received: b'request #3'
Client ---1 received: b'request #3'
Client ---1 received: b'request #3'
Req #2 sent..
Worker-server-1 received b'request #2' from b'---2'
Worker send 0 replys
Req #4 sent..
Worker-server-2 received b'request #4' from b'---1'
Worker send 3 replys
Client ---1 received: b'request #4'
Client ---1 received: b'request #4'
Req #3 sent..
Worker-server-3 received b'request #3' from b'---0'
Worker send 1 replys
Client ---1 received: b'request #4'
Client ---0 received: b'request #3'
```
3个client,　5个worker(server)处理. clients sent后,由中间的proxy round robin依次分配到每一个worker,worker随机回复n个reply.



## zmq_proxy

来来来，`zmq_proxy`终极封装，同样是实现上面各种功能的borker,比如shared queue:

```python
import zmq
context = zmq.Context.instance()
frontend = context.socket(zmq.ROUTER)
frontend.bind("tcp://127.0.0.1:5559")
backend = context.socket(zmq.DEALER)
backend.bind("tcp://127.0.0.1:5560")
zmq.proxy(frontend, backend)
# We never get here…
frontend.close()
backend.close()
context.term()
```
另外还可以做: 

fronend=XSUB, backend=XPUB的 Forwarder;

fronend=PULL, backend=PUSH的 Streamer;

