---
layout: page
title:
modified:
categories: Books
excerpt:
tags: [machine-learning]
---

<!-- TOC -->

- [模型](#模型)
  - [模型参数](#模型参数)
  - [假设](#假设)
- [求解问题](#求解问题)
  - [观测概率计算](#观测概率计算)
  - [预测状态序列](#预测状态序列)
  - [模型估计](#模型估计)

<!-- /TOC -->

### 模型

隐形马尔科夫模型是一个随机过程，也是一个概率模型。每个时刻 t 都是一个随机变量，如$s_{t},o_{t}$,B 前者是 t 时刻的状态随机变量，后者是 t 时刻的观测随机变量.

状态序列:$\left \{ s_{1}, s_{2},s_{3},..s_{t} \right \},s_{t}$为随机变量，取值空间为$\left \{ x_{1}, x_{2},x_{3}..x_{n} \right \}$;

观测序列:$\left \{ o_{1}, o_{2},o_{3},..o_{t} \right \},o_{t}$为随机变量，取值空间为$\left \{ y_{1}, y_{2},y_{3}..y_{m} \right \}$;

#### 模型参数

$\pi$是状态$s_{1}$的初始概率分布;

$A$是状态转移矩阵,转移发生在 t 到 t+1 的时刻，用条件变量来描述关系，即:
$P(s_{t+1}|s_{t})$
,$s_{i}$有 n 种取值，因此矩阵为 nxn 维.

$B$是观测概率矩阵，其元素表示时刻 t 处于某状态生成某个观测的概率,即:
$P(o_{t}|s_{t})$
,$o_{t}$有 m 种取值，因此矩阵是 nxm 维.

参数可以统一表示为$\lambda=(\pi,A,B)$.

#### 假设

假设 1:对状态序列，t 时刻状态只和 t-1 时刻有关，即马尔科夫假设:

$$P(s_{t}|s_{t-1},s_{t-2},s_{t-3},...s_{1}) = P(s_{t}|s_{t-1})$$

假设 2: 每个观测序列，只和引发他的状态序列有关，与其他无关:

$$P(o_{t}|s_{t},s_{t-2}...s_{1},o_{t-1}...o_{1}) = P(o_{t}|s_{t})$$

这两个假设是很强的假设，简化原模型的复杂度，也符合(能够近似)生活中的真实场景。

有了这 2 个假设，计算联合概率变得可能:

$$
P(\bar{o},\bar{s})&=P(s_{t},...s_{1},o_{t},...o_{1})
\\
&=P(s_{t},...s_{1})*P(o_{t},...o_{1}|s_{t},...s_{1})
\\
&=\prod_{l=1}^{t}P(s_{t}|s_{t-1})*\prod_{l=1}^{t}P(s_{t}|o_{t})
\end{align*}$$

还有个很重要的概率积分公式，作为下面的推导,

- 联合概率密度求边缘概率密度

### 求解问题

三大类问题，模型估计(学习问题)，求观测序列概率(概率计算)，预测状态序列(学习问题).最后一个也就是最常用的，语音识别，手写输入法等等具体问题的模型。

#### 观测概率计算

[这篇文章很清晰](https://blog.csdn.net/xmu_jupiter/article/details/50956389)
[还有这篇](https://www.cnblogs.com/nowgood/p/HMM.html)

前向和后向算法求概率:

![2018-04-22-18-41-09](https://images-1257933000.cos.ap-chengdu.myqcloud.com/2018-04-22-18-41-09.png)

由前后概率和后向概率求得的一些值，如:

观测 O 下某时刻 t 的状态$s_{t}=x_{j}$的概率.

观测 o 下某时刻 t 的状态$s_{t}=x_{j}$和下一时刻$s_{t+1}=x_{i}$联合概率.

![2018-04-22-18-42-14](https://images-1257933000.cos.ap-chengdu.myqcloud.com/2018-04-22-18-42-14.png)

#### 预测状态序列

主要是维特比算法.

[参考](http://www.cnblogs.com/pinard/p/6991852.html)

注意$\delta_{t}(i)$表示在时刻 t 的状态为$x_{i}$，对应的子路径取得的最大概率，是向量，不是一个最大值.

$$\delta_{t}(i)=\underset{s_{t-1},...s_{1}}{Max}\ P(s_{t}=x_{i},s_{t-1},..s_{1},o_{1},o_{2}..o_{t}) ,i=1,2,...N$$

可递推的求$\delta_{t+1}(i)$,根据 hmm 的假设条件:

$$
\delta_{t+1}(i) &=\underset{s_{t},...s_{1}}{Max}P(s_{t+1}=x_{i},s_{t},...o_{1},...o_{t+1})
\\
&=\underset{1\leq j\leq N}{Max}[\delta_{t}(i)*a_{ji}]*b_{i}(o_{t+1}),i=1,2,3,...N
\end{align*}$$

顺便算一下$\varphi_{t+1}(i)$:
$$

\varphi*{t+1}(i)=arg \underset{ 1\leq j \leq N}{max}\delta*{t}(i)_a\_{ji},i=1,2...N
\end{align_}\$\$

终止时,最后状态的最大概率:

$$
P^{*}=\underset{ 1 \leq i \leq N}{max}\delta_{t}(i)
\end{align*}
$$

最后一个预测的状态应该是所有状态里概率最大的一个

$$
index=arg\ \underset{ 1 \leq i \leq N}{max}[\delta_{t}(i)], index\ \epsilon [1,...N]
\end{align*}
$$

由最后的状态和$\varphi_{t}(i)$可以回溯上一个引起该最大概率的状态:

$$index_{t-1} = \varphi_{t}(index)$$

- 如果用贪心算法呢?

其实就是$\delta_{}(i)$不用向量，而是该向量里的最大值，作为从起点到当前时刻 t 的最后解，也就是已经求得了$s_{t}$的具体值，这样求得的序列并不是全局最优的，因为随着 t 的迭代，每一步都能确定一个$s_{t}$.

python 实现了算法，[这里](https://github.com/anribras/machine-learning/blob/master/note/hmm.ipynb)

#### 模型估计

无监督学习为主

[参考](https://blog.csdn.net/firparks/article/details/54934112)
